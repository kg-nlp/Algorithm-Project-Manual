---
sort: 2
---



# 框架环境



* [算法开发手册](https://kg-nlp.github.io/Algorithm-Project-Manual/算法框架/框架环境.html)

* [个人知乎](https://zhihu.com/people/zhangyj-n)

[TOC]

## 当前开发环境配置

![image-20231019093013321](框架环境.assets/image-20231019093013321.png)



![image-20231019093516114](框架环境.assets/image-20231019093516114.png)



![image-20231019093602841](框架环境.assets/image-20231019093602841.png)



![image-20231019093622643](框架环境.assets/image-20231019093622643.png)

![image-20231019093656312](框架环境.assets/image-20231019093656312.png)









## Pytorch

[pytorch-docker](https://github.com/cnstark/pytorch-docker)

### pytorch 1.7.0

> 算法框架的基础镜像

> 这个版本的cuda无法满足A800的显卡使用要求

```bash
docker run -it -d --name pytorch_env -p 8085:22 -p 8040:8040 -p 8030:8030 -p 8020:8020 --gpus all --shm-size 64g --restart=always pytorch/pytorch:1.7.0-cuda11.0-cudnn8-devel /bin/bash

apt-get update
apt-get install -y vim
apt-get install -y openssh-server
service ssh restart
root@b9d22b100490:/opt/conda/bin# ln -s /opt/conda/bin/python /usr/local/bin/python
root@b9d22b100490:/opt/conda/bin# ln -s /opt/conda/bin/pip /usr/local/bin/pip
```

> 设置容器启动时自动开启ssh服务

```bash
# 找到并打开文件/root/.bashrc
$ vim /root/.bashrc
# 在.bashrc末尾添加如下代码
$ service ssh start
```

> 重新commit 以及启动,启动时注意外挂数据卷,以及多暴露端口

```bash
docker commit pytorch_env registry.cn-beijing.aliyuncs.com/zhangyj-n/pytorch:1.7.0-cuda11.0-cudnn8-devel

docker run -it -d --name pytorch_env -p 8085:22  -p 8086:8086 -p 8087:8087 -p 8088:8088 -p 8089:8089 -p 8084:8084 \
-v /home/zhangyj/Algorithm_Frame:/home/Algorithm_Frame \
--shm-size 64g --restart=always --gpus all  -e NVIDIA_VISIBLE_DEVICES=all registry.cn-beijing.aliyuncs.com/zhangyj-n/pytorch:1.7.0-cuda11.0-cudnn8-devel /bin/bash
```



>  如果缺少动态库,参考工程内容 [🔨开发问题](https://kg-nlp.github.io/Algorithm-Project-Manual/工程内容/开发问题.html)

```bash
示例:
find / -name libcudart.so.10.2
/usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudart.so.10.2
拷贝至 /usr/lib/ 
```



### pytorch 1.13.0

* smp比赛镜像制作,custom环境

```bash
基于上面1.7.0开发,c++版本还是有些低了
registry.cn-beijing.aliyuncs.com/zhangyj-n/pytorch:1.13.0-cuda11.0-cudnn8-simple
docker run -it -d --name smp_env --gpus all  -e NVIDIA_VISIBLE_DEVICES=all registry.cn-beijing.aliyuncs.com/zhangyj-n/pytorch:1.13.0-cuda11.0-cudnn8-simple /bin/bash

docker exec -it smp_env bash  # 进入容器
apt-get update
apt-get install -y vim
apt-get install -y openssh-server  # 安装ssh服务
vi /etc/ssh/sshd_config  # 修改ssh配置文件如下(全部替换)
ggdG
"""
ChallengeResponseAuthentication no
UsePAM yes
X11Forwarding yes
PrintMotd no
AcceptEnv LANG LC_*
Subsystem    sftp    /usr/lib/openssh/sftp-server
PubkeyAuthentication yes
RSAAuthentication yes
PermitRootLogin yes
"""

service ssh restart  # 启动
passwd root  # 修改密码
root
cat /etc/passwd

root@b9d22b100490:/opt/conda/bin# ln -s /opt/conda/bin/python /usr/local/bin/python
root@b9d22b100490:/opt/conda/bin# ln -s /opt/conda/bin/pip /usr/local/bin/pip

which python  # 查找python解析器路径,使用pycharm远程连接时需要

apt-get install curl -y
apt-get install zip -y
apt-get install unzip -y
```

> 设置容器启动时自动开启ssh服务
```bash
# 找到并打开文件/root/.bashrc
$ vim /root/.bashrc
# 在.bashrc末尾添加如下代码
$ service ssh start
```

>  生成新镜像

```bash
docker commit -m 'update' registry.cn-beijing.aliyuncs.com/zhangyj-n/pytorch:1.13.0-cuda11.0-cudnn8-0823
```



> 已安装pip

```tex
transformers==4.31.0
modelscope==1.8.3
numpy==1.20.3
sentencepiece
torch==1.13.0
accelerate==0.21.0

python-docx==0.8.11
fastapi==0.101.1
openpyxl==3.1.2

elasticsearch==7.10.1
pymilvus==1.1.2
faiss-gpu==1.7.2
pdfplumber==0.10.2
pandas==2.0.3
```



> 启动

```bash
docker run -it -d --name custom_env \
-p 8015:22  -p 8001:8001 -p 8002:8002 -p 8003:8003 -p 8004:8004 -p 8005:8005 \
-v /data/zhangyj/custom_project:/workspace/custom_project \
--gpus all --shm-size 64g --restart=always \
-e NVIDIA_VISIBLE_DEVICES=all \
registry.cn-beijing.aliyuncs.com/zhangyj-n/pytorch:1.13.0-cuda11.0-cudnn8-0823 /bin/bash
```



* 在pytorch环境中安装paddle后再使用visualdl可视化日志

```bash
which visualdl
find / -name visualdl

# 创建软链接
ln -s /opt/conda/bin/visualdl /usr/local/bin/visualdl 

# 正常启动方式
/opt/conda/bin/visualdl --logdir=/home/Algorithm_Frame/LLM/ernie-1.0/output/ernie-3.0-micro-zh/runs/ --host= 0.0.0.0 --port=8010   打不开试试下面

# 上述无法打开,直接运行log文件
visualdl service upload --logdir ./runs/

# streamlit前端
ln -s /opt/conda/bin/streamlit /usr/local/bin/streamlit
```





### 个人开发colossalai

```
docker pull hpcaitech/colossalai:0.3.0
docker run -ti -id --name colossal_env --gpus all --rm --ipc=host hpcaitech/colossalai:0.3.0 bash

docker run -it -d --name colossal_env -p 8095:22 -p 7000:7000 -p 7010:7010 -p 7020:7020 -v /data/user/zhangyj/LLM:/workspace/LLM --gpus all --ipc=host hpcaitech/colossalai:0.3.0 bash
# 容器工作目录: /workspace
# 在当前容器中查找python 和 pip 的位置 /opt/conda/bin/python

# 原容器ssh无法启动,copy pytorch_env下的配置文件
docker cp pytorch_env:/etc/ssh/sshd_config /home/zhangyj/
docker cp /home/zhangyj/sshd_config colossal_env:/etc/ssh/sshd_config

apt-get install -y openssh-server
service ssh restart

# 创建新版本镜像
# 创建软连接
ln -s /opt/conda/bin/python /usr/local/bin/python
ln -s /opt/conda/bin/pip /usr/local/bin/pip

docker commit colossal_env registry.cn-beijing.aliyuncs.com/sg-gie/colossalai:0.3.0

# 重要pip包版本
torch==1.12.1
colossalai==0.3.0
```



```
docker run -it -d --name colossal_env -p 8095:22 -p 7000:7000 -p 7010:7010 -p 7020:7020 -v /data/user/zhangyj/LLM:/workspace/LLM --gpus all --ipc=host registry.cn-beijing.aliyuncs.com/sg-gie/colossalai:0.3.0 bash
service ssh restart

docker commit colossal_env registry.cn-beijing.aliyuncs.com/sg-gie/colossalai:20230712

docker run -it -d --name colossal_env -p 8095:22 -p 7000:7000 -p 7010:7010 -p 7020:7020 -p 7030:7030 -v /data/zhangyj/LLM:/workspace/LLM --gpus all --ipc=host registry.cn-beijing.aliyuncs.com/sg-gie/colossalai:20230712 bash

service ssh restart
```







## Paddle

### paddle:2.4.1

在A800无法运行,cuda不兼容

```bash
docker run -it -d --name paddle_env -p 8075:22 -v /home/zhangyj/EngineeringField/CDE:/home/EngineeringField/CDE --gpus all --shm-size 64g --restart=always -e NVIDIA_DRIVER_CAPABILITIES=compute,utility -e NVIDIA_VISIBLE_DEVICES=all paddlepaddle/paddle:2.4.1-gpu-cuda10.2-cudnn7.6-trt7.0 /bin/bash


远程访问 查看 上述链接（重点）
docker exec -it paddle_env bash
apt-get install openssh-server
service ssh restart

# 如果没有配置root密码时需要进行的操作
passwd root
root
cat /etc/passwd

pip install paddle_serving_app paddle_serving_client
pip install paddle-serving-server-gpu==0.8.3.post102 -i https://pypi.tuna.tsinghua.edu.cn/simple

which visualdl
find / -name visualdl
ln -s /usr/local/python3.7.0/bin/visualdl /usr/local/bin/visuadl
visualdl --logdir=./runs/ --port=8040

docker commit paddle_env registry.cn-beijing.aliyuncs.com/zhangyj-n/paddle:2.4.1-gpu-cuda10.2-cudnn7.6-trt7.0-20230223

docker run -it -d --name paddle_env_20230223 -p 8075:22 -p 8071:8071 -p 8072:8072 -p 8073:8073 -p 8874:8874 -v /home/zhangyj/EngineeringField/CDE:/home/EngineeringField/CDE --gpus all --shm-size 64g --restart=always -e NVIDIA_DRIVER_CAPABILITIES=compute,utility -e NVIDIA_VISIBLE_DEVICES=all registry.cn-beijing.aliyuncs.com/zhangyj-n/paddle:2.4.1-gpu-cuda10.2-cudnn7.6-trt7.0-20230223
```



### paddle:2.5.0



```bash
docker run -it -d --name paddle_env -p 8075:22 -p 18040:18040 -p 18030:18030 -p 18020:18020 -p 18010:18010  -v /data/zhangyj/CDE:/home/zhangyj/CDE --gpus all --shm-size 64g --restart=always -e NVIDIA_DRIVER_CAPABILITIES=compute,utility -e NVIDIA_VISIBLE_DEVICES=all paddlepaddle/paddle:2.5.0-gpu-cuda11.7-cudnn8.4-trt8.4 /bin/bash

切换阿里源 
apt-get update

远程访问 查看 上述链接（重点）
docker exec -it paddle_env bash
apt-get install -y openssh-server
service ssh restart

# 如果没有配置root密码时需要进行的操作
passwd root
root
cat /etc/passwd

pip install paddle_serving_app paddle_serving_client
pip install paddle-serving-server-gpu==0.8.3.post112 -i https://pypi.tuna.tsinghua.edu.cn/simple

which visualdl
find / -name visualdl

ln -s /usr/local/python3.7.0/bin/visualdl /usr/local/bin/visuadl
visualdl --logdir=./runs/ --port=8040

vim /root/.bashrc
service ssh start


docker commit paddle_env registry.cn-beijing.aliyuncs.com/zhangyj-n/paddle:2.5.0-gpu-cuda11.7-cudnn8.4-trt8.4

docker run -it -d --name paddle_env -p 8075:22 -p 8076:8076 -p 8077:8077 -p 8079:8079 -p 8074:8074  -v /data/zhangyj/CDE:/home/zhangyj/CDE --gpus all --shm-size 64g --restart=always -e NVIDIA_DRIVER_CAPABILITIES=compute,utility -e NVIDIA_VISIBLE_DEVICES=all registry.cn-beijing.aliyuncs.com/zhangyj-n/paddle:2.5.0-gpu-cuda11.7-cudnn8.4-trt8.4 /bin/bash
```



## pytorch-paddle

### ==paddle_torch:base-1.13.0-2.4.2-11.7==

```
docker run -it -d --name test_env --gpus all -e NVIDIA_VISIBLE_DEVICES=all cnstark/pytorch:1.13.0-py3.9.12-cuda11.7.1-devel-ubuntu20.04 /bin/bash

docker exec -it test_env bash  # 进入容器

pip install pip -U

ubuntu更新清华源
vi /etc/apt/sources.list (下面的源)
apt-get update

apt-get install -y vim
apt-get install -y openssh-server  # 安装ssh服务
vi /etc/ssh/sshd_config  # 修改ssh配置文件如下(全部替换)
ggdG
"""
ChallengeResponseAuthentication no
UsePAM yes
X11Forwarding yes
PrintMotd no
AcceptEnv LANG LC_*
Subsystem    sftp    /usr/lib/openssh/sftp-server
PubkeyAuthentication yes
RSAAuthentication yes
PermitRootLogin yes
"""

# 找到并打开文件/root/.bashrc
$ vim /root/.bashrc
# 在.bashrc末尾添加如下代码
$ service ssh start

service ssh restart  # 启动
passwd root  # 修改密码
root
cat /etc/passwd

which python  # 查找python解析器路径,使用pycharm远程连接时需要

root@b9d22b100490:/opt/conda/bin# ln -s /opt/conda/bin/python /usr/local/bin/python
root@b9d22b100490:/opt/conda/bin# ln -s /opt/conda/bin/pip /usr/local/bin/pip

find / -name nvcc
ln -s /usr/local/cuda/bin/nvcc /usr/local/bin/nvcc

apt-get install curl -y
apt-get install zip -y
apt-get install unzip -y

永久更新清华源
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
```



> ubuntu更新阿里云

```
阿里源
deb https://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse
deb-src https://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse

deb https://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse
deb-src https://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse

deb https://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse
deb-src https://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse

# deb https://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse
# deb-src https://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse

deb https://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse
deb-src https://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse


清华源
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse multiverse
```



> 安装必要包

````
transformers==4.31.0
modelscope==1.8.3
numpy==1.20.3
sentencepiece
accelerate==0.21.0
python-docx==0.8.11
fastapi==0.101.1
openpyxl==3.1.2
elasticsearch==7.10.1
pymilvus==1.1.2
faiss-gpu==1.7.2
pdfplumber==0.10.2
pandas==2.0.3
matplotlib==3.7.2
visualdl==2.4.2
paddlenlp==2.5.2  # 安装后,把依赖包装好,再卸载
hnswlib==0.7.0

pip install paddlepaddle-gpu==2.4.2.post117 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html
````



> 生成新镜像并推送,运行

```
docker commit test_env registry.cn-beijing.aliyuncs.com/zhangyj-n/paddle_torch:base-1.13.0-2.4.2-11.7

docker run -it -d --name paddle_torch_env -p 8075:22 -p 8076:8076 -p 8077:8077 -p 8079:8079 -p 8074:8074  -v /data/zhangyj/CDE:/home/zhangyj/CDE --gpus all --shm-size 64g --restart=always -e NVIDIA_DRIVER_CAPABILITIES=compute,utility -e NVIDIA_VISIBLE_DEVICES=all registry.cn-beijing.aliyuncs.com/zhangyj-n/paddle_torch:base-1.13.0-2.4.2-11.7 /bin/bash

docker run -it -d --name custom_env \
-p 8015:22  -p 8001:8001 -p 8002:8002 -p 8003:8003 -p 8004:8004 -p 8005:8005 \
-v /data/zhangyj/custom_project:/workspace/custom_project \
--gpus all --shm-size 64g --restart=always \
-e NVIDIA_VISIBLE_DEVICES=all \
registry.cn-beijing.aliyuncs.com/zhangyj-n/paddle_torch:base-1.13.0-2.4.2-11.7 /bin/bash
```



#### 更新 -v1

registry.cn-beijing.aliyuncs.com/zhangyj-n/paddle_torch:v1-1.13.0-2.4.2-11.7 (还未打包)

* pip包

```
nltk==3.8.1
loguru==0.7.1
gensim==4.3.2
typing==3.7.4.3
streamlit==1.26.0
pybind11==2.11.1
pytorch-crf==0.7.2
python-dotenv==1.0.0
torchsummary==1.5.1
xlsxwriter==3.1.3
pypinyin==0.49.0
Levenshtein==0.21.1
simhash==2.1.2
tiktoken==0.5.1
bs4==0.0.1
harvesttext==0.8.2.1
fuzzywuzzy==0.18.0
python-levenshtein==0.21.1
xlrd==2.0.1
tritonclient==2.10.0
paddle-serving-server-gpu== 0.9.0.post1028
paddle-serving-app==0.9.0
paddle-serving-client==0.9.0
triton-model-analyzer==1.31.0.9384447  # 使用perf analyzer缺少动态库
numexpr 
fast-tokenizer-python
x2paddle
deepspeed  前提有nvcc
sse_starlette-1.6.5
peft>=0.4.0
trl>=0.7.2
rouge_chinese
gradio==3.38.0
jsonlines
transformers_stream_generator==0.0.4
bitsandbytes==0.41.0
```



* apt包

```
apt-get install screen
apt install fonts-noto-cjk 
# fonts-anonymous-pro 目前装不上

pip install xformers 升级torch
```





## triton-server

参考模型加速

* 基础镜像 paddlepaddle/triton_paddle:21.10

```
根据paddlepaddle/triton_paddle:21.10生成下面的nvidia-tensorrt环境

apt-get install onnx-graphsurgeon
onnx==1.13.1   -i https://pypi.tuna.tsinghua.edu.cn/simple
pip install 'pycuda<2021.1'  # 这个没安装成功,似乎不影响结果
pip install nvidia-pyindex
pip install nvidia-tensorrt==8.4.3.1 -i https://pypi.tuna.tsinghua.edu.cn/simple  
pip install nvidia-tensorrt==8.4.1.5 -i https://pypi.tuna.tsinghua.edu.cn/simple  # 最重要的是这个要安装成功

在上面环境进行onnx 到 tensorrt的转换
docker commit -m 'pip paddle' triton_zyj registry.cn-beijing.aliyuncs.com/sg-gie/triton-paddle--pkm-04:21.10-py3  # 没问题

registry.cn-beijing.aliyuncs.com/zhangyj-n/triton-paddle:21.10-py 
docker run -it -d --gpus '"device=0"' --name triton_zyj --shm-size="32g" --restart=always -p 7001:7001 -p 7002:7002 -p 7003:7003 -p 7004:7004 -v /data/zhangyj/custom_project/model_inference:/model_inference registry.cn-beijing.aliyuncs.com/zhangyj-n/triton-paddle:21.10-py3 bash 

```

* 基础镜像: nvcr.io/nvidia/tritonserver:22.07-py3

  ```
  在 nvcr.io/nvidia/tritonserver:22.07-py3 部署tensorrt模型
  
  docker run -it -d --gpus '"device=0"' --name triton_zyj_test --shm-size="32g" --restart=always -p 6001:6001 -p 6002:6002 -p 6003:6003 -p 
  6004:6004 -v /data/zhangyj/custom_project/model_inference:/model_inference nvcr.io/nvidia/tritonserver:22.07-py3 bash
  
  pip install --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple
  
  pip list
  
  pip install paddlepaddle-gpu==2.4.2.post117 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html  
  pip install paddlenlp==2.5.2 fast-tokenizer-python -i https://pypi.tuna.tsinghua.edu.cn/simple
  pip install fast-tokenizer-python -i https://pypi.tuna.tsinghua.edu.cn/simple
  
  pip install nvidia-tensorrt==8.4.1.5 -i https://pypi.tuna.tsinghua.edu.cn/simple  
  
  export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11/lib64  # 可以在本容器内进行onnx转trt 以及部署
  vim ~/.bashrc  # 添加内容 
  source ~/.bashrc
  可以在上面环境进行onnx 到 tensorrt的转换
  
  docker commit -m 'add nvidia-tensorrt8.4.1.5' triton_zyj_test registry.cn-beijing.aliyuncs.com/sg-gie/tensorrt-paddle:22.07   # 在pkm-04上部署tensorrt模型
  docker commit -m 'add nvidia-tensorrt8.4.1.5' triton_zyj_test registry.cn-beijing.aliyuncs.com/zhangyj-n/tensorrt-paddle:22.07
  ```
  
  



## jupyter



[docker-github](https://github.com/jupyter/docker-stacks)

[jupyter-docker-stacks](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/recipes.html?highlight=password#using-sudo-within-a-container)

```bash
docker run -it -d -p 10000:8888 --user root -e GRANT_SUDO=yes --restart=always --name jupyter_data -v "${PWD}":/home/jovyan/work jupyter/datascience-notebook:85f615d5cafa

docker run -it -d -p 10000:8888 --user root -e GRANT_SUDO=yes --restart=always --name jupyter_data -v /data/zhangyj/custom_project:/home/jovyan/work jupyter/datascience-notebook:85f615d5cafa
```



```bash
(base) jovyan@f43a5217f92c:~$ jupyter server list
Currently running servers:
http://8dd83dac7297:8888/?token=3bbda5fc70f418d74d70e1b81090c04d472cfee3c53ea4af :: /home/jovyan

'''中间省略升级apt,安装其他服务'''

chown -Rf jovyan:users ./
```





## SSH访问

> 当启动容器后 外部无法访问时

**安装ssh**

```
apt-get install -y openssh-server

无法安装
apt-get update
```

**2.备份ssh的配置文件**

```
sudo cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak
```

**3.新装的ssh需要修改配置文件**

```
vi /etc/ssh/sshd_config
```

　　配置文件修改这几处地方　

```
ChallengeResponseAuthentication no
UsePAM yes
X11Forwarding yes
PrintMotd no
AcceptEnv LANG LC_*
Subsystem    sftp    /usr/lib/openssh/sftp-server
PubkeyAuthentication yes
RSAAuthentication yes
PermitRootLogin yes
```

**4.启动ssh**

```
service ssh start            # * Starting OpenBSD Secure Shell server sshd<br># 或者<br>/etc/init.d/ssh start        # * Starting OpenBSD Secure Shell server sshd
```

　　如果提示错误信息中包含**could not load host key** 则需要重新生成 key

```
sudo rm /etc/ssh/ssh*key # 先移除旧的key dpkg-reconfigure openssh-server
```

　　生成之后需要重启SSH服务使新的密钥生效：   

```
service ssh restart          # * Restarting OpenBSD Secure Shell server sshd<br># 或者/etc/init.d/ssh restart       # * Restarting OpenBSD Secure Shell server sshd
```

　　启动、停止和重启ssh的命令如下

```
/etc/init.d/ssh start         # * Starting OpenBSD Secure Shell server sshd /etc/init.d/ssh stop          # * Stopping OpenBSD Secure Shell server sshd /etc/init.d/ssh restart       # * Restarting OpenBSD Secure Shell server sshd
```



**5.查看服务状态**

```
service ssh status # * sshd is running  显示此内容则表示启动正常
```

**6.查看ssh是否启动**

```
ps -e | grep ssh

　　如果ssh已经启动则会提示

469 ?        00:00:00 sshd
```

**7.设置ssh开机自启动**

容器内设置

```
# 找到并打开文件/root/.bashrc
$ vim /root/.bashrc
# 在.bashrc末尾添加如下代码
$ service ssh start
```





## **内核、nvidia驱动、Cuda、cudann版本对应关系及安装**

centos :

yum更新-内核升级-与nvidia驱动不兼容

以pkm-01为例

**lspci | grep -i nvidia  查看GPU**

```
3b:00.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)
86:00.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)
af:00.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)
d8:00.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)
```

**uname -m && cat /etc/\*release**  查看环境信息

```
x86_64
CentOS Linux release 7.9.2009 (Core)
NAME="CentOS Linux"
VERSION="7 (Core)"
ID="centos"
ID_LIKE="rhel fedora"
VERSION_ID="7"
PRETTY_NAME="CentOS Linux 7 (Core)"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:centos:centos:7"
HOME_URL="https://www.centos.org/"
BUG_REPORT_URL="https://bugs.centos.org/"

CENTOS_MANTISBT_PROJECT="CentOS-7"
CENTOS_MANTISBT_PROJECT_VERSION="7"
REDHAT_SUPPORT_PRODUCT="centos"
REDHAT_SUPPORT_PRODUCT_VERSION="7"

CentOS Linux release 7.9.2009 (Core)
CentOS Linux release 7.9.2009 (Core)
```



**gcc --version**

```
gcc (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
Copyright (C) 2017 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE
```



**uname -r**

内核头和内核开发包

```
3.10.0-1160.90.1.el7.x86_64
Note: If you perform a system update which changes the version of the linux kernel being used, make sure to rerun the commands below to ensure you have the correct kernel headers and kernel development packages installed. Otherwise, the CUDA Driver will fail to work with the new kernel.
```

centos 安装linux内核头和内核开发包

**cuda toolkit**

```
distribution-specific packages (RPM and Deb packages), 
or a distribution-independent package (runfile packages)
```

倾向使用前者

```
The libcuda.so library is installed in the /usr/lib{,64}/nvidia directory. For pre-existing projects which use libcuda.so, it may be useful to add a symbolic link from libcuda.so in the /usr/lib{,64} directory.
```

**NVIDIA CUDA Toolkit Release Notes**

[cuda版本和nvidia内核版本](https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html)

![image-20230904204839067](框架环境.assets/image-20230904204839067.png)

```
wget https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda-repo-rhel7-12-1-local-12.1.1_530.30.02-1.x86_64.rpm
sudo rpm -i cuda-repo-rhel7-12-1-local-12.1.1_530.30.02-1.x86_64.rpm
sudo yum clean all
sudo yum -y install nvidia-driver-latest-dkms
sudo yum -y install cuda
```



[**cuda驱动**](https://www.nvidia.com/Download/Find.aspx)

![image-20230904204915091](框架环境.assets/image-20230904204915091.png)



到好的环境中查看linux内核版本,查看nvidia驱动版本,查看cuda版本

[**https://blog.csdn.net/A15216110998/article/details/113402172**](https://blog.csdn.net/A15216110998/article/details/113402172)  **这个文件不错**

根据教程

第二步，使用nvcc -V检查驱动和cuda

```
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Feb_14_21:12:58_PST_2021
Cuda compilation tools, release 11.2, V11.2.152
Build cuda_11.2.r11.2/compiler.29618528_0
```

第三步，查看已安装驱动的版本信息

```
ls /usr/src | grep nvidia
nvidia-530.30.02
```

docker run gpu 无法使用是,记得装nvidia-container-runtime

```
安装NVIDIA-CONTAINER-RUNTIME
在https://nvidia.github.io/nvidia-container-runtime/查看支持的操作系统和版本，并根据对应选项，添加源，因为我是centos7，所以添加方式为：

distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-container-runtime/$distribution/nvidia-container-runtime.repo | \
sudo tee /etc/yum.repos.d/nvidia-container-runtime.repo

然后直接yum install 就可以了
sudo yum install nvidia-container-runtime
进行测试，如果能成功出现显卡信息就可以了

sudo systemctl restart docker

docker run -it --rm --gpus all centos nvidia-smi
```

**安装完后再重启  sudo reboot**



## conda环境配置



**Linux下安装miniconda**

https://blog.csdn.net/m0_46336568/article/details/127836072

```
#第一步下载miniconda安装包 
#安装包连接https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/，查找相应安装包
wget -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-py39_4.9.2-Linux-x86_64.sh
#第二步安装
bash Miniconda3-py39_4.9.2-Linux-x86_64.sh
#第三部配置conda镜像
source ~/.bashrc
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda
conda config --set show_channel_urls yes
#第四步创建一个名称为python38的环境，python版本等于3.8
conda create -n tf2.3torch1.7 python=3.8
conda create -n paddle_env python=3.8
#第五步 激活环境
source activate python38
```



**创建用户和密码**

```
useradd zhangyj
passwd zhangyj
zhangyj-n  zhangyj-n
接下来安装pip包
```



**配置源**

```
# 设置conda命令启动
vi ~/.bashrc
内容如下
export PATH=/home/zhangyj/miniconda3/bin/:$PATH


#设置pip清华源
#用户的文件夹下新建目录.pip，并在目录新建配置文件pip.conf
#命令
mkdir ~/.pip
cd ~/.pip
vi pip.conf
内容如下
[global]
index-url=https://pypi.tuna.tsinghua.edu.cn/simple
[install]
trusted-host=pypi.tuna.tsinghua.edu.cn
disable-pip-version-check = true
timeout = 6000
```



**导出虚拟环境pip包**

```
conda install -n env_name python=3.7

pip批量导出包含环境中所有组件的requirements.txt文件
pip freeze > requirements.txt

pip批量安装requirements.txt文件中包含的组件依赖
pip install -r requirements.txt

conda批量导出包含环境中所有组件的requirements.txt文件
conda list -e > requirements.txt

conda批量安装requirements.txt文件中包含的组件依赖
conda install --yes --file requirements.txt
```



## python 安装



### Python3.7

```
安装python & python安装
centos安装python3
1) 首先安装依赖包
 yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel libffi-devel
2) 下载python3安装包
[root@python tools]# wget https://www.python.org/ftp/python/3.7.4/Python-3.7.4.tgz
3) 解压
[root@python tools]# tar xvzf Python-3.7.4.tgz 
tar xvzf Python-3.7.4.tgz
4) 创建文件夹把python3安装在里面
[root@python tools]# mkdir -p /usr/local/python3.7.4
[root@python tools]# cd Python-3.7.4
[root@python Python-3.7.4]# ./configure --prefix=/usr/local/python3.7.4/
[root@python Python-3.7.4]# make && make install
5) 建立软连接
[root@python Python-3.7.4]# ln -s /usr/local/python3.7.4/bin/python3.7 /usr/bin/python3
[root@python Python-3.7.4]# ln -s /usr/local/python3.7.4/bin/pip3.7 /usr/bin/pip3
 ln -s /usr/local/python3.7.4/bin/python3.7 /usr/local/bin/python 3
 ln -s /usr/local/python3.7.4/bin/pip3.7 /usr/local/bin/pip3
6) 验证和测试
[root@python Python-3.7.4]# python3.7.4
Python 3.7.4 (default, Jul 26 2019, 04:16:54) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>
```

```
 原容器自带软连接
 ln -s /usr/local/python3.7.0/bin/python3.7 /usr/bin/python
 ln -s /usr/local/python3.7.0/bin/pip3.7 /usr/bin/pip
 
 ln -s /usr/local/python3.7.0/bin/python3.7 /usr/local/bin/python 
 ln -s /usr/local/python3.7.0/bin/pip3.7 /usr/local/bin/pip
```



### Python3.8

**3.8.8 还没测试过**

```
2) 下载python3安装包
wget https://www.python.org/ftp/python/3.8.8/Python-3.8.8.tgz
3) 解压
tar xvzf Python-3.8.8.tgz
4) 创建文件夹把python3安装在里面
mkdir -p /usr/local/python3
cd Python-3.8.8
./configure --prefix=/usr/local/python3/
make && make install
5) 建立软连接
[root@python Python-3.8.8]# ln -s /usr/local/python3/bin/python3.7 /usr/bin/python3
[root@python Python-3.8.8]# ln -s /usr/local/python3/bin/pip3.7 /usr/bin/pip3
6) 验证和测试
[root@python Python-3.8.8]# python3
Python 3.7.4 (default, Jul 26 2019, 04:16:54) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>
```



## 基础镜像



### **python_debian_gcc:2.0.0**

Python和pip版本，位置

```
/usr/local/lib/python3.7/site-packages
```

已有环境

````
gevent==21.1.2
tqdm==4.53.0
Flask==1.1.2
supervisor==4.2.1
PyMySQL==0.10.1
cryptography==3.3.1
pandas==1.2.4
xlrd==1.2.0
openpyxl==3.0.5
psutil==5.8.0
sqlalchemy==1.4.20
thrift-sasl==0.4.3
thrift==0.15.0
sasl==0.3.1
pyhive==0.6.4
gunicorn==20.0.4
apscheduler==3.8.1
时区已更改，有vim，有telnet net-tools
````

### **python_debian_gcc:3.0.0**

主要是可以提供paddle client

```
在python_debian_gcc:2.0.0基础上创建

requirements.txt包含下面内容
paddle_serving_client==0.9.0
paddle_serving_server==0.8.3
sklearn==0.0
requests==2.28.2
cn2an
scipy
regex
elasticsearch==7.10.1
jionlp

cd /data/zhangyj/CDE/cde_project
docker run -it -d --name python_debian_gcc registry.cn-beijing.aliyuncs.com/sg-gie/python_debian_gcc:2.0.0
docker cp requirements.txt python_debian_gcc:/requirements.txt
docker exec -it python_debian_gcc bash
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/
exit
docker commit -a 'zhangyj-n' -m '使用paddle服务' python_debian_gcc registry.cn-beijing.aliyuncs.com/sg-gie/python_debian_gcc:3.0.0
```



### **milvus_cpu:1.1.1**

```
docker run -d --name milvus_cpu_1.1.1 \
-p 19530:19530 \
-p 19121:19121 \
registry.cn-beijing.aliyuncs.com/sg-gie/milvus_cpu:1.1.1
```



### **neo4j-apoc:3.5.20**

含neo4j算法库

```
docker run -d --name neo4j_class -p 7476:7474 -p 7689:7687 \
--env NEO4J_AUTH=neo4j/glodon registry.cn-beijing.aliyuncs.com/sg-gie/neo4j-apoc:3.5.20
```

